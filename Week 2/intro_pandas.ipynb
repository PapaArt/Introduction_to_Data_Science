{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introduction to Pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This week we're going to deepen our investigation to how Python can be used to manipulate, clean, and query data by looking at the Pandas data tool kit. Pandas was created by Wes McKinney in 2008, and is an open source project under a very permissive license. As an open source project it's got a strong community, with over one hundred software developers all committing code to help make it better. Before pandas existed we had only a hodge podge of tools to use, such as numpy, the python core libraries, and some python statistical tools. But pandas has quickly become the defacto library for representing relational data for data scientists.\n",
    "\n",
    "I want to take a moment here to introduce the question answersing site Stack Overflow. Stack Overflow is used broadly within the software development community to post questions about programming, programming languages, and programming toolkits. What's special about Stack Overflow is that it's heavily curated by the community. And the Pandas community, in particular, uses it as their number one resource for helping new members. It's quite possible if you post a question to Stack Overflow, and tag it as being Pandas and Python related, that a core Pandas developer will actually respond to your question. In addition to posting questions, Stack Overflow is a great place to go to see what issues people are having and how they can be solved. You can learn a lot from browsing Stacks at Stack Overflow and with pandas, this is where the developer community is.\n",
    "\n",
    "A second resource you might want to consider are books. In 2012 Wes McKinney wrote the definitive Pandas reference book called Python for Data Analysis and published by O'Reilly, and it's recently been update to a second edition. I consider this the go to book for understanding how Pandas works. I also appreciate the more brief book \"Learning the Pandas Library\" by Matt Harrison. It's not a comprehensive book on data analysis and statistics. But if you just want to learn the basics of Pandas and want to do so quickly, I think it's a well laid out volume and it can be had for a good price.\n",
    "\n",
    "The field of data science is rapidly changing. There's new toolkits and method being created everyday. It can be tough to stay on top of it all. Marco Rodriguez and Tim Golden maintain a wonderful blog aggregator site called Planet Python. You can visit the webpage at planetpython.org, subscribe with an RSS reader, or get the latest articles from the @PlanetPython Twitter feed. There's lots of regular Python data science contributors, and I highly recommend it if you follow RSS feeds.\n",
    "\n",
    "Here's my last plug on how to deepen your learning. Kyle Polich runs an excellent podcast called Data Skeptic. It isn't Python based per se, but it's well produced and it has a wonderful mixture of interviews with experts in the field as well as short educational lessons. Much of the word he describes is specific to machine learning methods. But if that's something you are planning to explore through this specialization this course is in, I would really encourage you to subscribe to his podcast.\n",
    "\n",
    "That's it for a little bit of an introduction to this week of the course. Next we're going to dive right into Pandas library and talk about the series data structure."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Series Data Structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this lecture we're going to explore the pandas Series structure. By the end of this lecture you should be \n",
    "familiar with how to store and manipulate single dimensional indexed data in the Series object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The series is one of the core data structures in pandas. You think of it a cross between a list and a dictionary.\n",
    "The items are all stored in an order and there's labels with which you can retrieve them. An easy way to \n",
    "visualize this is two columns of data. The first is the special index, a lot like keys in a dictionary. While the\n",
    "second is your actual data. It's important to note that the data column has a label of its own and can be \n",
    "retrieved using the .name attribute. This is different than with dictionaries and is useful when it comes to \n",
    "merging multiple columns of data. And we'll talk about that later on in the course."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import pandas to get started\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     Alice\n",
       "1      Papa\n",
       "2    Raíssa\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# As you might expect, you can create a series by passing in a list of values. \n",
    "# When you do this, Pandas automatically assigns an index starting with zero and\n",
    "# sets the name of the series to None. Let's work on an example of this.\n",
    "\n",
    "# One of the easiest ways to create a series is to use an array-like object, like \n",
    "# a list. \n",
    "\n",
    "# Here I'll make a list of the three of students, Alice, Jack, and Molly, all as strings\n",
    "students = ['Alice', 'Papa', 'Raíssa']\n",
    "\n",
    "# Now we just call the Series function in pandas and pass in the students\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is a Series object which is nicely rendered to the screen. We see here that \n",
    "# the pandas has automatically identified the type of data in this Series as \"object\" and\n",
    "# set the dytpe parameter as appropriate. We see that the values are indexed with integers,\n",
    "# starting at zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2\n",
       "1    4\n",
       "2    9\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# We don't have to use strings. If we passed in a list of whole numbers, for instance, \n",
    "# we could see that panda sets the type to int64. Underneath panda stores series values in a \n",
    "# typed array using the Numpy library. This offers significant speedup when processing data \n",
    "# versus traditional python lists.\n",
    "\n",
    "# Lets create a little list of numbers\n",
    "numbers = [2, 4, 9]\n",
    "# And turn that into a series\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we see on my architecture that the result is a dtype of int64 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Alice\n",
       "1     Papa\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# There's some other typing details that exist for performance that are important to know. \n",
    "# The most important is how Numpy and thus pandas handle missing data. \n",
    "\n",
    "# In Python, we have the none type to indicate a lack of data. But what do we do if we want \n",
    "# to have a typed list like we do in the series object?\n",
    "\n",
    "# Underneath, pandas does some type conversion. If we create a list of strings and we have \n",
    "# one element, a None type, pandas inserts it as a None and uses the type object for the \n",
    "# underlying array. \n",
    "\n",
    "# Let's recreate our list of students, but leave the last one as a None\n",
    "students = ['Alice', 'Papa', None]\n",
    "# And lets convert this to a series\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# However, if we create a list of numbers, integers or floats, and put in the None type,\n",
    "# pandas automatically converts this to a special floating point value designated as NaN, \n",
    "# which stands for \"Not a Number\".\n",
    "\n",
    "# So lets create a list with a None value in it\n",
    "numbers = [1, 2, None]\n",
    "# And turn that into a series\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll notice a couple of things. First, NaN is a different value. Second, pandas\n",
    "# set the dytpe of this series to floating point numbers instead of object or ints. That's\n",
    "# maybe a bit of a surprise - why not just leave this as an integer? Underneath, pandas\n",
    "# represents NaN as a floating point number, and because integers can be typecast to\n",
    "# floats, pandas went and converted our integers to floats. So when you're wondering why the\n",
    "# list of integers you put into a Series is not floats, it's probably because there is some\n",
    "# missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# For those who might not have done scientific computing in Python before, it is important\n",
    "# to stress that None and NaN might be being used by the data scientist in the same way, to\n",
    "# denote missing data, but that underneath these are not represented by pandas in the same\n",
    "# way.\n",
    "\n",
    "# NaN is *NOT* equivalent to None and when we try the equality test, the result is False.\n",
    "\n",
    "# Lets bring in numpy which allows us to generate an NaN value\n",
    "import numpy as np\n",
    "# And lets compare it to None\n",
    "np.NaN == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# It turns out that you actually can't do an equality test of NAN to itself. When you do, \n",
    "# the answer is always False. \n",
    "\n",
    "np.NaN == np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Instead, you need to use special functions to test for the presence of not a number, \n",
    "# such as the Numpy library isnan().\n",
    "\n",
    "np.isnan(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So keep in mind when you see NaN, it's meaning is similar to None, but it's a \n",
    "# numeric value and treated differently for efficiency reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice     English\n",
       "Papa         Math\n",
       "Raissa    Biology\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Let's talk more about how pandas' Series can be created. While my list might be a common \n",
    "# way to create some play data, often you have label data that you want to manipulate. \n",
    "# A series can be created directly from dictionary data. If you do this, the index is \n",
    "# automatically assigned to the keys of the dictionary that you provided and not just \n",
    "# incrementing integers.\n",
    "\n",
    "# Here's an example using some data of students and their classes.\n",
    "\n",
    "students_scores = {'Alice': 'English',\n",
    "                    'Papa': 'Math',\n",
    "                    'Raissa': 'Biology'}\n",
    "s = pd.Series(students_scores)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that, since it was string data, pandas set the data type of the series to \"object\".\n",
    "# We see that the index, the first column, is also a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Alice', 'Papa', 'Raissa'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Once the series has been created, we can get the index object using the index attribute.\n",
    "\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you play more with pandas you'll notice that a lot of things are implemented as numpy\n",
    "# arrays, and have the dtype value set. This is true of indicies, and here pandas infered\n",
    "# that we were using objects for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     (Alice, Brown)\n",
       "1       (Papa, Blue)\n",
       "2    (Raissa, White)\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Now, this is kind of interesting. The dtype of object is not just for strings, but for\n",
    "# arbitrary objects. Lets create a more complex type of data, say, a list of tuples.\n",
    "students = [(\"Alice\", \"Brown\"), (\"Papa\", \"Blue\"), (\"Raissa\", \"White\")]\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that each of the tuples is stored in the series object, and the type is object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice     English\n",
       "Papa         Math\n",
       "Raissa    Biology\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# You can also separate your index creation from the data by passing in the index as a \n",
    "# list explicitly to the series.\n",
    "\n",
    "s = pd.Series(['English', 'Math', 'Biology'], index = ['Alice', 'Papa', 'Raissa'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice    English\n",
       "Papa        Math\n",
       "Lucas        NaN\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# So what happens if your list of values in the index object are not aligned with the keys \n",
    "# in your dictionary for creating the series? Well, pandas overrides the automatic creation \n",
    "# to favor only and all of the indices values that you provided. So it will ignore from your \n",
    "# dictionary all keys which are not in your index, and pandas will add None or NaN type values \n",
    "# for any index value you provide, which is not in your dictionary key list.\n",
    "\n",
    "# Here's and example. I'll pass in a dictionary of three items, in this case students and\n",
    "# their courses\n",
    "students_scores = {'Alice': 'English',\n",
    "                    'Papa': 'Math',\n",
    "                    'Raissa': 'Biology'}\n",
    "# When I create the series object though I'll only ask for an index with three students, and\n",
    "# I'll exclude Jack\n",
    "s = pd.Series(students_scores, index=['Alice', 'Papa', 'Lucas'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is that the Series object doesn't have Jack in it, even though he was in our\n",
    "# original dataset, but it explicitly does have Sam in it as a missing value."
   ]
  },
  {
   "source": [
    "In this lecture we've explored the pandas Series data structure. You've seen how to create a series from lists \n",
    "and dictionaries, how indicies on data work, and the way that pandas typecasts data including missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Querying Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this lecture, we'll talk about one of the primary data types of the Pandas library, the Series. You'll learn\n",
    "about the structure of the Series, how to query and merge Series objects together, and the importance of thinking \n",
    "about parallelization when engaging in data science programming."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice     English\n",
       "Papa         Math\n",
       "Raissa    Biology\n",
       "Lucas     History\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# A pandas Series can be queried either by the index position or the index label. If you don't give an \n",
    "# index to the series when querying, the position and the label are effectively the same values. To \n",
    "# query by numeric location, starting at zero, use the iloc attribute. To query by the index label, \n",
    "# you can use the loc attribute. \n",
    "\n",
    "# Lets start with an example. We'll use students enrolled in classes coming from a dictionary\n",
    "import pandas as pd\n",
    "students_classes = {'Alice': 'English',\n",
    "                    'Papa': 'Math',\n",
    "                    'Raissa': 'Biology',\n",
    "                    'Lucas': 'History'}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice     English\n",
       "Papa         Math\n",
       "Raissa    Biology\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# So, for this series, if you wanted to see the fourth entry we would we would use the iloc \n",
    "# attribute with the parameter 3.\n",
    "s.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Math'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# If you wanted to see what class Molly has, we would use the loc attribute with a parameter \n",
    "# of Molly.\n",
    "s.loc['Papa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that iloc and loc are not methods, they are attributes. So you don't use \n",
    "# parentheses to query them, but square brackets instead, which is called the indexing operator. \n",
    "# In Python this calls get or set for an item depending on the context of its use.\n",
    "\n",
    "# This might seem a bit confusing if you're used to languages where encapsulation of attributes, \n",
    "# variables, and properties is common, such as in Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Pandas tries to make our code a bit more readable and provides a sort of smart syntax using \n",
    "# the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, \n",
    "# the operator will behave as if you want it to query via the iloc attribute\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Math'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# If you pass in an object, it will query as if you wanted to use the label based loc attribute.\n",
    "s['Papa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what happens if your index is a list of integers? This is a bit complicated and Pandas can't \n",
    "# determine automatically whether you're intending to query by index position or index label. So \n",
    "# you need to be careful when using the indexing operator on the Series itself. The safer option \n",
    "# is to be more explicit and use the iloc or loc attributes directly.\n",
    "\n",
    "# Here's an example using class and their classcode information, where classes are indexed by \n",
    "# classcodes, in the form of integers\n",
    "class_code = {99: 'English',\n",
    "              100: 'Math',\n",
    "              101: 'Biology',\n",
    "              102: 'Physics'}\n",
    "s = pd.Series(class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-25dcb490ae44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# an index of zero, instead we have to call iloc explicitly if we want the first item.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# If we try and call s[0] we get a key error because there's no item in the classes list with \n",
    "# an index of zero, instead we have to call iloc explicitly if we want the first item.\n",
    "\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, that didn't call s.iloc[0] underneath as one might expect, instead it \n",
    "# generates an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know how to get data out of the series, let's talk about working with the data. A common \n",
    "# task is to want to consider all of the values inside of a series and do some sort of \n",
    "# operation. This could be trying to find a certain number, or summarizing data or transforming \n",
    "# the data in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# A typical programmatic approach to this would be to iterate over all the items in the series, \n",
    "# and invoke the operation one is interested in. For instance, we could create a Series of \n",
    "# integers representing student grades, and just try and get an average grade\n",
    "\n",
    "grades = pd.Series([60, 70, 80, 90])\n",
    "\n",
    "total = 0\n",
    "for grade in grades:\n",
    "    total += grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works, but it's slow. Modern computers can do many tasks simultaneously, especially, \n",
    "# but not only, tasks involving mathematics.\n",
    "\n",
    "# Pandas and the underlying numpy libraries support a method of computation called vectorization. \n",
    "# Vectorization works with most of the functions in the numpy library, including the sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# Here's how we would really write the code using the numpy sum method. First we need to import \n",
    "# the numpy module\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Then we just call np.sum and pass in an iterable item. In this case, our panda series.\n",
    "\n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    765\n",
       "1    223\n",
       "2    680\n",
       "3     76\n",
       "4     60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "# Now both of these methods create the same value, but is one actually faster? The Jupyter \n",
    "# Notebook has a magic function which can help. \n",
    "\n",
    "# First, let's create a big series of random numbers. This is used a lot when demonstrating \n",
    "# techniques with Pandas\n",
    "numbers = pd.Series(np.random.randint(0, 1000, 10000))\n",
    "\n",
    "# Now lets look at the top five items in that series to make sure they actually seem random. We\n",
    "# can do this with the head() function\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# We can actually verify that length of the series is correct using the len function\n",
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we're confident now that we have a big series. The ipython interpreter has something called\n",
    "# magic functions begin with a percentage sign. If we type this sign and then hit the Tab key, you\n",
    "# can see a list of the available magic functions. You could write your own magic functions too, \n",
    "# but that's a little bit outside of the scope of this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're actually going to use what's called a cellular magic function. These start with two \n",
    "# percentage signs and wrap the code in the current Jupyter cell. The function we're going to use \n",
    "# is called timeit. This function will run our code a few times to determine, on average, how long \n",
    "# it takes.\n",
    "\n",
    "# Let's run timeit with our original iterative code. You can give timeit the number of loops that \n",
    "# you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because \n",
    "# we're recording this. Note that in order to use a cellular magic function, it has to be the first \n",
    "# line in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.01 ms ± 66.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total += number\n",
    "\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not bad. Timeit ran the code and it doesn't seem to take very long at all. Now let's try with \n",
    "# vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "92.1 µs ± 16.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow! This is a pretty shocking difference in the speed and demonstrates why one should be \n",
    "# aware of parallel computing features and start thinking in functional programming terms.\n",
    "# Put more simply, vectorization is the ability for a computer to execute multiple instructions\n",
    "# at once, and with high performance chips, especially graphics cards, you can get dramatic\n",
    "# speedups. Modern graphics cards can run thousands of instructions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    765\n",
       "1    223\n",
       "2    680\n",
       "3     76\n",
       "4     60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# A Related feature in pandas and numpy is called broadcasting. With broadcasting, you can \n",
    "# apply an operation to every value in the series, changing the series. For instance, if we\n",
    "# wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
    "# directly on the Series object. \n",
    "\n",
    "# Let's look at the head of our series\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    769\n",
       "1    227\n",
       "2    684\n",
       "3     80\n",
       "4     64\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "numbers += 2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'set_value'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-0928790c9bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# now for the item which is returned, lets call set_value()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# And we can check the result of this computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'set_value'"
     ]
    }
   ],
   "source": [
    "# The procedural way of doing this would be to iterate through all of the items in the \n",
    "# series and increase the values directly. Pandas does support iterating through a series \n",
    "# much like a dictionary, allowing you to unpack values easily.\n",
    "\n",
    "# We can use the iteritems() function which returns a label and value\n",
    "for label, value in numbers.iteritems():\n",
    "    # now for the item which is returned, lets call set_value()\n",
    "    numbers.set_value(label, value+2)\n",
    "# And we can check the result of this computation\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the result is the same, though you may notice a warning depending upon the version of\n",
    "# pandas being used. But if you find yourself iterating pretty much *any time* in pandas,\n",
    "# you should question whether you're doing things in the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at some speed comparisons. First, lets try five loops using the iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75.8 ms ± 23.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# we'll create a blank new series of items to deal with\n",
    "s = pd.Series(np.random.randint(0, 1000, 1000))\n",
    "# And we'll just rewrite our loop from above.\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label] = value + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try that using the broadcasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "446 µs ± 134 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# We need to recreate a series\n",
    "s = pd.Series(np.random.randint(0, 1000, 1000))\n",
    "# And we just broadcast with +=\n",
    "s += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazing. Not only is it significantly faster, but it's more concise and even easier \n",
    "# to read too. The typical mathematical operations you would expect are vectorized, and the \n",
    "# numpy documentation outlines what it takes to create vectorized functions of your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last note on using the indexing operators to access series data. The .loc attribute lets \n",
    "# you not only modify data in place, but also add new data as well. If the value you pass in as \n",
    "# the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
    "# While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
    "# change the underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "History    102\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "# Here's an example using a Series of a few numbers. \n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# We could add some new value, maybe a university course\n",
    "s.loc['History'] = 102\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that mixed types for data values or index labels are no problem for Pandas. Since \n",
    "# \"History\" is not in the original list of indices, s.loc['History'] essentially creates a \n",
    "# new element in the series, with the index named \"History\", and the value of 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Up until now I've shown only examples of a series where the index values were unique. I want \n",
    "# to end this lecture by showing an example where index values are not unique, and this makes \n",
    "# pandas Series a little different conceptually then, for instance, a relational database.\n",
    "\n",
    "# Lets create a Series with students and the courses which they have taken\n",
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'})\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Now lets create a Series just for some new student Kelly, which lists all of the courses\n",
    "# she has taken. We'll set the index to Kelly, and the data to be the names of courses.\n",
    "kelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Finally, we can append all of the data in this new Series to the first using the .append()\n",
    "# function.\n",
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "\n",
    "# This creates a series which has our original people in it as well as all of Kelly's courses\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# There are a couple of important considerations when using append. First, Pandas will take \n",
    "# the series and try to infer the best data types to use. In this example, everything is a string, \n",
    "# so there's no problems here. Second, the append method doesn't actually change the underlying Series\n",
    "# objects, it instead returns a new series which is made up of the two appended together. This is\n",
    "# a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
    "# one you should come to expect. By printing the original series we can see that that series hasn't\n",
    "# changed.\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Finally, we see that when we query the appended series for Kelly, we don't get a single value, \n",
    "# but a series itself. \n",
    "all_students_classes.loc['Kelly']"
   ]
  },
  {
   "source": [
    "In this lecture, we focused on one of the primary data types of the Pandas library, the Series. You learned how \n",
    "to query the Series, with .loc and .iloc, that the Series is an indexed data structure, how to merge two Series \n",
    "objects together with append(), and the importance of vectorization.\n",
    "\n",
    "There are many more methods associated with the Series object that we haven't talked about. But with these basics \n",
    "down, we'll move on to talking about the Panda's two-dimensional data structure, the DataFrame. The DataFrame is \n",
    "very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend \n",
    "the majority of your time working with when cleaning and aggregating data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Frame and Data Structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The DataFrame data structure is the heart of the Panda's library. It's a primary object that you'll be working \n",
    "with in data analysis and cleaning tasks.\n",
    "\n",
    "The DataFrame is conceptually a two-dimensional series object, where there's an index and multiple columns of \n",
    "content, with each column having a label. In fact, the distinction between a column and a row is really only a \n",
    "conceptual distinction. And you can think of the DataFrame itself as simply a two-axes labeled array."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by importing our pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to jump in with an example. Lets create three school records for students and their \n",
    "# class grades. I'll create each as a series which has a student name, the class name, and the score. \n",
    "record1 = pd.Series({'Name': 'Alice',\n",
    "                        'Class': 'Physics',\n",
    "                        'Score': 85})\n",
    "record2 = pd.Series({'Name': 'Jack',\n",
    "                        'Class': 'Chemistry',\n",
    "                        'Score': 82})\n",
    "record3 = pd.Series({'Name': 'Helen',\n",
    "                        'Class': 'Biology',\n",
    "                        'Score': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name      Class  Score\n",
       "school1  Alice    Physics     85\n",
       "school2   Jack  Chemistry     82\n",
       "school1  Helen    Biology     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Like a Series, the DataFrame object is index. Here I'll use a group of series, where each series \n",
    "# represents a row of data. Just like the Series function, we can pass in our individual items\n",
    "# in an array, and we can pass in our index values as a second arguments\n",
    "df = pd.DataFrame([record1, record2, record3],\n",
    "                  index=['school1', 'school2', 'school1'])\n",
    "\n",
    "# And just like the Series we can use the head() function to see the first several rows of the\n",
    "# dataframe, including indices from both axes, and we can use this to verify the columns and the rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll notice here that Jupyter creates a nice bit of HTML to render the results of the\n",
    "# dataframe. So we have the index, which is the leftmost column and is the school name, and\n",
    "# then we have the rows of data, where each row has a column header which was given in our initial\n",
    "# record dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name      Class  Score\n",
       "school1  Alice    Physics     85\n",
       "school2   Jack  Chemistry     82\n",
       "school1  Helen    Biology     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# An alternative method is that you could use a list of dictionaries, where each dictionary \n",
    "# represents a row of data.\n",
    "\n",
    "students = [{'Name': 'Alice',\n",
    "              'Class': 'Physics',\n",
    "              'Score': 85},\n",
    "            {'Name': 'Jack',\n",
    "             'Class': 'Chemistry',\n",
    "             'Score': 82},\n",
    "            {'Name': 'Helen',\n",
    "             'Class': 'Biology',\n",
    "             'Score': 90}]\n",
    "\n",
    "# Then we pass this list of dictionaries into the DataFrame function\n",
    "df = pd.DataFrame(students, index=['school1', 'school2', 'school1'])\n",
    "# And lets print the head again\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Name          Jack\n",
       "Class    Chemistry\n",
       "Score           82\n",
       "Name: school2, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# Similar to the series, we can extract data using the .iloc and .loc attributes. Because the \n",
    "# DataFrame is two-dimensional, passing a single value to the loc indexing operator will return \n",
    "# the series if there's only one row to return.\n",
    "\n",
    "# For instance, if we wanted to select data associated with school2, we would just query the \n",
    "# .loc attribute with one parameter.\n",
    "df.loc['school2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# You'll note that the name of the series is returned as the index value, while the column \n",
    "# name is included in the output.\n",
    "\n",
    "# We can check the data type of the return using the python type function.\n",
    "type(df.loc['school2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name    Class  Score\n",
       "school1  Alice  Physics     85\n",
       "school1  Helen  Biology     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# It's important to remember that the indices and column names along either axes horizontal or \n",
    "# vertical, could be non-unique. In this example, we see two records for school1 as different rows.\n",
    "# If we use a single value with the DataFrame lock attribute, multiple rows of the DataFrame will \n",
    "# return, not as a new series, but as a new DataFrame.\n",
    "\n",
    "# Lets query for school1 records\n",
    "df.loc['school1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# And we can see the the type of this is different too\n",
    "type(df.loc['school1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "school1    Alice\n",
       "school1    Helen\n",
       "Name: Name, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# One of the powers of the Panda's DataFrame is that you can quickly select data based on multiple axes.\n",
    "# For instance, if you wanted to just list the student names for school1, you would supply two \n",
    "# parameters to .loc, one being the row index and the other being the column name.\n",
    "\n",
    "# For instance, if we are only interested in school1's student names\n",
    "df.loc['school1', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       school1    school2  school1\n",
       "Name     Alice       Jack    Helen\n",
       "Class  Physics  Chemistry  Biology\n",
       "Score       85         82       90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>school1</th>\n      <th>school2</th>\n      <th>school1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Name</th>\n      <td>Alice</td>\n      <td>Jack</td>\n      <td>Helen</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>Physics</td>\n      <td>Chemistry</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>Score</th>\n      <td>85</td>\n      <td>82</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Remember, just like the Series, the pandas developers have implemented this using the indexing\n",
    "# operator and not as parameters to a function.\n",
    "\n",
    "# What would we do if we just wanted to select a single column though? Well, there are a few\n",
    "# mechanisms. Firstly, we could transpose the matrix. This pivots all of the rows into columns\n",
    "# and all of the columns into rows, and is done with the T attribute\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "school1    Alice\n",
       "school2     Jack\n",
       "school1    Helen\n",
       "Name: Name, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# Then we can call .loc on the transpose to get the student names only\n",
    "df.T.loc['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "school1    Alice\n",
       "school2     Jack\n",
       "school1    Helen\n",
       "Name: Name, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# However, since iloc and loc are used for row selection, Panda reserves the indexing operator \n",
    "# directly on the DataFrame for column selection. In a Panda's DataFrame, columns always have a name. \n",
    "# So this selection is always label based, and is not as confusing as it was when using the square \n",
    "# bracket operator on the series objects. For those familiar with relational databases, this operator \n",
    "# is analogous to column projection.\n",
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Name'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b44ae13e0b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# In practice, this works really well since you're often trying to add or drop new columns. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this also means that you get a key error if you try and use .loc with a column name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "# In practice, this works really well since you're often trying to add or drop new columns. However,\n",
    "# this also means that you get a key error if you try and use .loc with a column name\n",
    "df.loc['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# Note too that the result of a single column projection is a Series object\n",
    "type(df['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "school1    Alice\n",
       "school1    Helen\n",
       "Name: Name, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Since the result of using the indexing operator is either a DataFrame or Series, you can chain \n",
    "# operations together. For instance, we can select all of the rows which related to school1 using\n",
    "# .loc, then project the name column from just those rows\n",
    "df.loc['school1']['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# If you get confused, use type to check the responses from resulting operations\n",
    "print(type(df.loc['school1'])) #should be a DataFrame\n",
    "print(type(df.loc['school1']['Name'])) #should be a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaining, by indexing on the return type of another index, can come with some costs and is\n",
    "# best avoided if you can use another approach. In particular, chaining tends to cause Pandas \n",
    "# to return a copy of the DataFrame instead of a view on the DataFrame. \n",
    "# For selecting data, this is not a big deal, though it might be slower than necessary. \n",
    "# If you are changing data though this is an important distinction and can be a source of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name  Score\n",
       "school1  Alice     85\n",
       "school2   Jack     82\n",
       "school1  Helen     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# Here's another approach. As we saw, .loc does row selection, and it can take two parameters, \n",
    "# the row index and the list of column names. The .loc attribute also supports slicing.\n",
    "\n",
    "# If we wanted to select all rows, we can use a colon to indicate a full slice from beginning to end. \n",
    "# This is just like slicing characters in a list in python. Then we can add the column name as the \n",
    "# second parameter as a string. If we wanted to include multiple columns, we could do so in a list. \n",
    "# and Pandas will bring back only the columns we have asked for.\n",
    "\n",
    "# Here's an example, where we ask for all the names and scores for all schools using the .loc operator.\n",
    "df.loc[:,['Name', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at that again. The colon means that we want to get all of the rows, and the list\n",
    "# in the second argument position is the list of columns we want to get back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's selecting and projecting data from a DataFrame based on row and column labels. The key \n",
    "# concepts to remember are that the rows and columns are really just for our benefit. Underneath \n",
    "# this is just a two axes labeled array, and transposing the columns is easy. Also, consider the \n",
    "# issue of chaining carefully, and try to avoid it, as it can cause unpredictable results, where \n",
    "# your intent was to obtain a view of the data, but instead Pandas returns to you a copy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['school1'] not found in axis\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-8e7d67ac2ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# the drop function returns to you a copy of the DataFrame with the given rows removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'school1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['school1'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Before we leave the discussion of accessing data in DataFrames, lets talk about dropping data.\n",
    "# It's easy to delete data in Series and DataFrames, and we can use the drop function to do so. \n",
    "# This function takes a single parameter, which is the index or row label, to drop. This is another \n",
    "# tricky place for new users -- the drop function doesn't change the DataFrame by default! Instead,\n",
    "# the drop function returns to you a copy of the DataFrame with the given rows removed.\n",
    "\n",
    "df.drop('school1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name      Class  Score\n",
       "school1  Alice    Physics     85\n",
       "school2   Jack  Chemistry     82\n",
       "school1  Helen    Biology     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# But if we look at our original DataFrame we see the data is still intact.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Class  Score\n",
       "school1    Physics     85\n",
       "school2  Chemistry     82\n",
       "school1    Biology     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# Drop has two interesting optional parameters. The first is called inplace, and if it's \n",
    "# set to true, the DataFrame will be updated in place, instead of a copy being returned. \n",
    "# The second parameter is the axes, which should be dropped. By default, this value is 0, \n",
    "# indicating the row axis. But you could change it to 1 if you want to drop a column.\n",
    "\n",
    "# For example, lets make a copy of a DataFrame using .copy()\n",
    "copy_df = df.copy()\n",
    "# Now lets drop the name column in this copy\n",
    "copy_df.drop(\"Name\", inplace=True, axis=1)\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Score\n",
       "school1     85\n",
       "school2     82\n",
       "school1     90"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# There is a second way to drop a column, and that's directly through the use of the indexing \n",
    "# operator, using the del keyword. This way of dropping data, however, takes immediate effect \n",
    "# on the DataFrame and does not return a view.\n",
    "del copy_df['Class']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Name      Class  Score ClassRanking\n",
       "school1  Alice    Physics     85         None\n",
       "school2   Jack  Chemistry     82         None\n",
       "school1  Helen    Biology     90         None"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n      <th>ClassRanking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Finally, adding a new column to the DataFrame is as easy as assigning it to some value using\n",
    "# the indexing operator. For instance, if we wanted to add a class ranking column with default \n",
    "# value of None, we could do so by using the assignment operator after the square brackets.\n",
    "# This broadcasts the default value to the new column immediately.\n",
    "\n",
    "df['ClassRanking'] = None\n",
    "df"
   ]
  },
  {
   "source": [
    "In this lecture you've learned about the data structure you'll use the most in pandas, the DataFrame. The \n",
    "dataframe is indexed both by row and column, and you can easily select individual rows and project the columns \n",
    "you're interested in using the familiar indexing methods from the Series class. You'll be gaining a lot of \n",
    "experience with the DataFrame in the content to come."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}